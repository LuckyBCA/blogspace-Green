# Benchmark Sources for LLM Comparisons (benchmark-sources.md)

This file contains verified, reliable sources of benchmarking and performance data for large language models (LLMs). It is meant to support the automated generation of accurate, SEO-friendly, comparison blog posts for RankLLMs.com.

## âœ… Official Model Pages

### Meta LLaMA
- [LLaMA 3.1 Blog (Meta)](https://ai.meta.com/blog/meta-llama-3-1/)
- [LLaMA 3.2 Blog (Meta)](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/)

### OpenAI GPT Series
- [GPT-4 Technical Report](https://openai.com/research/gpt-4)
- [GPT-4o Introduction](https://openai.com/index/gpt-4o/)

### Anthropic Claude Series
- [Claude 3 Technical Overview](https://www.anthropic.com/news/claude-3-family)

### Google DeepMind Gemini
- [Gemini 1.5 Report](https://deepmind.google/technologies/gemini/gemini-1-5/)
- [Gemini 1.0 Benchmark Results](https://blog.google/technology/ai/google-gemini-ai/)

### Mistral AI
- [Mistral Official Website](https://mistral.ai/news/)

### Qwen (Alibaba Cloud)
- [Qwen Model Overview](https://github.com/QwenLM/Qwen)

### xAI Grok
- [Grok Introduction (via xAI)](https://x.ai/blog)

## âœ… Benchmark Aggregator Sources

### LMSYS (Chatbot Arena)
- [Chatbot Arena Leaderboard](https://chat.lmsys.org/)
- [LMSYS GitHub Benchmarks](https://github.com/lm-sys/FastChat/blob/main/docs/benchmark.md)

### Hugging Face Open LLM Leaderboard
- [HuggingFace Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

### Papers With Code
- [Open LLM Evaluation Leaderboard](https://paperswithcode.com/leaderboards)

## âœ… Performance Benchmarks

### Common Benchmarks Used
- MMLU (Massive Multitask Language Understanding)
- ARC (AI2 Reasoning Challenge)
- HellaSwag
- TruthfulQA
- GSM8K (Math)
- HumanEval (Code Generation)

### Dataset Definitions
- [BIG-Bench](https://github.com/google/BIG-bench)
- [Eleuther AI Tasks](https://github.com/EleutherAI/lm-evaluation-harness)

## âœ… Image Assets / Visuals
- [Leonardo AI](https://leonardo.ai/) â€“ free realistic and illustrative image generation
- [OpenArt](https://openart.ai/)
- [Pixabay (Free stock)](https://pixabay.com)

## âœ… Tips for Use in Automations
- Extract data tables from benchmark pages (MMLU, Arena, etc.)
- Use scores like accuracy %, parameter count, FLOPs, and dataset types
- Make comparison tables for each article auto-generated
- Always cite original sources at the end of each article

---

**Last updated:** June 2025

> ðŸ“Œ Use this file as permanent context for Copilot, GPT, or N8N/AI automations to generate factual articles. Keep updating monthly.

